{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First of all giving permission to google colab so that it can access the files "
      ],
      "metadata": {
        "id": "YCSVzDkCXaC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "QAF3e66QyJhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2b61d8-a4d6-49ef-bf5e-727cf537e1af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "Xd5eKVLcFoiL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the data\n"
      ],
      "metadata": {
        "id": "KCIIPOEwQhYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividing the data in test and training data but first getting total number of rows, then only adding 90% of it to training data.\n",
        "data=[]\n",
        "number_of_rows=0\n",
        "with open('A_Z Handwritten Data.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    for row in reader:\n",
        "      number_of_rows+=1\n",
        "      data.append(list(row))"
      ],
      "metadata": {
        "id": "0hlu1l2NFFWs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segregating the data"
      ],
      "metadata": {
        "id": "WbOUs3sXck_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# segregating the read data\n",
        "# train_data=[]\n",
        "# test_data=[]\n",
        "# counter=0\n",
        "# for i in data:\n",
        "#   counter+=1\n",
        "#   if counter<=(0.9*number_of_rows):\n",
        "#     train_data.append(i)\n",
        "#   else: \n",
        "#     test_data.append(i)\n",
        "\n",
        "#THIS IS COMMENTED OUT FOR THE REASON EXPLAINED IN BELOW COMMENTS"
      ],
      "metadata": {
        "id": "w2eY7fMqSMLh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Now the next step is to calculate p(y=k) where k belongs to [0,25]\n",
        "# dict1={}\n",
        "# counter_list=[]  \n",
        "# #will store the first column of each row and then we will use counter to count number of times a particular one appears and then divide by total number to get probability by favourable/total\n",
        "\n",
        "# for i in train_data:\n",
        "#   counter_list.append(i[0])\n",
        "\n",
        "# #Now our next step is to assign the number and the probability of each as key value pair in dictionary, we are using dictionary because it uses hash mapping ang take less time to fetch data\n",
        "# counter_set=set(counter_list)   #just to remove the duplicates and see all the labels that have been covered in the training data\n",
        "# print(counter_set)\n",
        "# #OUTPUT=['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '3', '4', '5', '6', '7', '8', '9']\n",
        "# #so we can see if we use training data then not all the labels between 0 to 25 are covered. So for calculating P(Y=k) we need to first shuffle the data and then segregate it and that's why above part was commented out"
      ],
      "metadata": {
        "id": "SnvsfEJDRO-2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "xlJjCa66be7K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segregating the read data\n",
        "train_data=[]\n",
        "test_data=[]\n",
        "counter=0\n",
        "for i in data:\n",
        "  counter+=1\n",
        "  if counter<=(0.9*number_of_rows):\n",
        "    train_data.append(i)\n",
        "  else: \n",
        "    test_data.append(i)"
      ],
      "metadata": {
        "id": "S7y8gwYrbkcq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculation P(Y=k)"
      ],
      "metadata": {
        "id": "R1_ZF7TOcopL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now the next step is to calculate p(y=k) where k belongs to [0,25]\n",
        "dict1={}\n",
        "counter_list=[]  \n",
        "#will store the first column of each row and then we will use counter to count number of times a particular one appears and then divide by total number to get probability by favourable/total\n",
        "\n",
        "for i in train_data:\n",
        "  counter_list.append(i[0])\n",
        "\n",
        "#Now our next step is to assign the number and the probability of each as key value pair in dictionary, we are using dictionary because it uses hash mapping ang take less time to fetch data\n",
        "counter_set=set(counter_list)   #just to remove the duplicates and see all the labels that have been covered in the training data. These will help in adding keys to the dictionary"
      ],
      "metadata": {
        "id": "C7pxjodkbsou"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating P(y=k) and adding to dictionary\n",
        "for i in counter_set:\n",
        "  probability=counter_list.count(i)/len(counter_list)\n",
        "  dict1[i]=round(probability,6)"
      ],
      "metadata": {
        "id": "iLtfSPcKcRtf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dict1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xLWO2UQdEIX",
        "outputId": "afdda1e0-5a33-4c06-987a-1205be46f4cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'14': 0.155081, '20': 0.077922, '9': 0.022858, '21': 0.011232, '19': 0.06039, '16': 0.015623, '18': 0.130437, '11': 0.031091, '10': 0.015042, '1': 0.023186, '23': 0.016817, '6': 0.015474, '8': 0.002983, '0': 0.037186, '15': 0.052228, '4': 0.030674, '25': 0.016178, '13': 0.051091, '5': 0.003153, '22': 0.028773, '17': 0.031142, '3': 0.027246, '12': 0.033108, '7': 0.019328, '24': 0.029122, '2': 0.062633}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addressing the problems of creation of bins, initially taking it be bin size of 8. "
      ],
      "metadata": {
        "id": "DJXXSMulSzEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_dict={}  #again using dictionary for associating "
      ],
      "metadata": {
        "id": "CKvIrywaTK7x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key=0\n",
        "for i in range(0,255):\n",
        "  if 32*key<=i and i<32*(key+1):\n",
        "    bin_dict[i]=key\n",
        "  else:\n",
        "    bin_dict[i]=key+1 #because otherwise numbers such as 32,64 where if statements are not satisfied would never be added to dictionary.\n",
        "    key+=1\n",
        "#so we are creating a bin size of 8 i.e. all the pixels which were taking values between 0 to 255 will now be scaled down to take values between 0 to 7\n",
        "#so that means the scaling will take 32 numbers at a time to divide 256 over 8 parts, so numbers in range 0 to 31 will come to 0 then between 32 to 63 to 1 and so on... "
      ],
      "metadata": {
        "id": "p7aOXGPJTRpQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bin_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7Wr5yv9UfTO",
        "outputId": "3019273a-25d7-42b0-d333-9a797fbad0bf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 65: 2, 66: 2, 67: 2, 68: 2, 69: 2, 70: 2, 71: 2, 72: 2, 73: 2, 74: 2, 75: 2, 76: 2, 77: 2, 78: 2, 79: 2, 80: 2, 81: 2, 82: 2, 83: 2, 84: 2, 85: 2, 86: 2, 87: 2, 88: 2, 89: 2, 90: 2, 91: 2, 92: 2, 93: 2, 94: 2, 95: 2, 97: 3, 98: 3, 99: 3, 100: 3, 101: 3, 102: 3, 103: 3, 104: 3, 105: 3, 106: 3, 107: 3, 108: 3, 109: 3, 110: 3, 111: 3, 112: 3, 113: 3, 114: 3, 115: 3, 116: 3, 117: 3, 118: 3, 119: 3, 120: 3, 121: 3, 122: 3, 123: 3, 124: 3, 125: 3, 126: 3, 127: 3, 129: 4, 130: 4, 131: 4, 132: 4, 133: 4, 134: 4, 135: 4, 136: 4, 137: 4, 138: 4, 139: 4, 140: 4, 141: 4, 142: 4, 143: 4, 144: 4, 145: 4, 146: 4, 147: 4, 148: 4, 149: 4, 150: 4, 151: 4, 152: 4, 153: 4, 154: 4, 155: 4, 156: 4, 157: 4, 158: 4, 159: 4, 161: 5, 162: 5, 163: 5, 164: 5, 165: 5, 166: 5, 167: 5, 168: 5, 169: 5, 170: 5, 171: 5, 172: 5, 173: 5, 174: 5, 175: 5, 176: 5, 177: 5, 178: 5, 179: 5, 180: 5, 181: 5, 182: 5, 183: 5, 184: 5, 185: 5, 186: 5, 187: 5, 188: 5, 189: 5, 190: 5, 191: 5, 193: 6, 194: 6, 195: 6, 196: 6, 197: 6, 198: 6, 199: 6, 200: 6, 201: 6, 202: 6, 203: 6, 204: 6, 205: 6, 206: 6, 207: 6, 208: 6, 209: 6, 210: 6, 211: 6, 212: 6, 213: 6, 214: 6, 215: 6, 216: 6, 217: 6, 218: 6, 219: 6, 220: 6, 221: 6, 222: 6, 223: 6, 225: 7, 226: 7, 227: 7, 228: 7, 229: 7, 230: 7, 231: 7, 232: 7, 233: 7, 234: 7, 235: 7, 236: 7, 237: 7, 238: 7, 239: 7, 240: 7, 241: 7, 242: 7, 243: 7, 244: 7, 245: 7, 246: 7, 247: 7, 248: 7, 249: 7, 250: 7, 251: 7, 252: 7, 253: 7, 254: 7, 255: 7, 32: 1, 64: 2, 96: 3, 128: 4, 160: 5, 192: 6, 224: 7, 256: 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now once we have done this we need to change all the data in our training set according to our bin size."
      ],
      "metadata": {
        "id": "4YzqbptGXCsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#so in the train_data list each element is a list which has 785 entries where the first entry is the label and remaining 784 as pixels and we can verify that\n",
        "print(len(train_data[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR_imyXZXMVm",
        "outputId": "19c98728-6469-47fb-b30c-0b1bc17e40c1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#so to convert all 784 pixels according to our bin size, we will take all data by iterating through them and replace them with their corresponding value in the bin dictionary\n",
        "\n",
        "for i in train_data:\n",
        "  for j in range(1,785): #starting from index 1 as index 0 is label and we only need to change the pixel data\n",
        "    i[j]=bin_dict[int(i[j])]\n"
      ],
      "metadata": {
        "id": "uRYA77Y2YDjS"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}